@author Seth Falcon <seth@opscode.com>
@copyright 2012 Opscode, Inc.
@title stats_hero your metrics and logging helper
@doc

== Overview ==

The `stats_hero' application can help you instrument your Erlang
application with metrics that will be reported to `estatsd' and
browsable in Graphite. There is also support for request logging (to a
file via `fast_log') and you may want to use this feature so that your
application's logs follow Opscode's logging convention.

== How to instrument your code to collect metrics ==

Include the `stats_hero.hrl' file. Wrap calls to upstream services
using the `?SH_TIME(ReqId, Mod, Fun, Args)' macro. Here's an example
from the `chef_db' module:

```
fetch_user(#context{reqid = ReqId, otto_connection = _Server} = _Context, UserName) ->
    case ?SH_TIME(ReqId, chef_sql, fetch_user, (UserName)) of
        {ok, not_found} ->
            not_found;
        {ok, #chef_user{}=User} ->
            User;
        {error, Error} ->
            {error, Error}
    end.
'''

The `ReqId' argument is a request id generated by our front-end load
balancers (via nginx module). It is used to lookup a helper process
that aggregates metrics before sending them to estatsd. The macro
calls {@link stats_hero:ctime/3} and the `stats_hero' side of the computation is a
no-op if no worker process is found that matches the specified request
id. Note, however, that determining if there is a match requires the
`stats_hero' application to be running. So instrumented code will run
fine with a missing or crashed worker process, but will not function
if the `stats_hero' application is not running.

In order to generate consistent labels in graphite, `stats_hero'
maintains a mapping of module names to upstream names. The `Mod'
argument serves a double purpose: it is used as the module name for
the call to evaluate (and time) and it gets mapped to a generic
upstream name (e.g. `chef_sql' maps to `rdbms'). A future enhancement
would put this mapping in app config for `stats_hero'. If `Mod' is not
recognized, an error is raised.

== Sending metrics and logging requests with stats_hero ==

At the begining of your request, start a `stats_hero' worker process
using {@link stats_hero_worker_sup:new_worker/1} like this:

```
    Config = [{estatsd_host, EstatsdServer},
              {estatsd_port, EstatsdPort},
              {request_id, ReqId},
              {org_name, OrgName},
              {my_app, "ChefAPI"},
              {request_label, RequestLabel},
              {request_action, atom_to_list(wrq:method(Req))},
              {upstream_prefixes, [<<"mysql">>, <<"couch">>, <<"authz">>, <<"solr">>]}],

stats_hero_worker_sup:new_worker(Config)
'''

Then proceed to call code instrumented as described above. When your
request is complete, tell your worker process and it will send a total
time for the request to estatsd along with details on cummulative time
spent in the specified upstreams. Use {@link stats_hero:report_metrics/2}
for that. For example,

```
stats_hero:report_metrics(ReqId, Code),
'''

Where `ReqId' is your request id as a binary and `Code' is an HTTP
response code (or similar integer).

You can have `stats_hero' log a standard tuple-formatted log message
summarizing your request by calling {@link
stats_hero:log_request/3}. Here's the usage from `chef_rest_wm':

```
log_request(Req, #base_state{reqid = ReqId,
                             log_msg = Msg,
                             organization_name = Org}) ->
    Status = wrq:response_code(Req),
    Tuples = [{req_id, ReqId},
              {status, Status},
              {org_name, Org},
              {method, wrq:method(Req)},
              {path, wrq:raw_path(Req)},
              {user, wrq:get_req_header("x-ops-userid", Req)},
              {msg, {raw, Msg}}],
    stats_hero:log_request(erchef, log_level(Status), Tuples).

log_level(Code) when Code >= 500 ->
    err;
log_level(_) ->
    info.
'''

Note that you must have already configured `fast_log' to have an entry
for the logger that you specify.

Finally, you need to tell the `stats_hero' worker that you're done
with it. Use {@link stats_her:stop_worker/1} for that.

== Design notes ==

The stats_hero workers are started using a `simple_one_for_one'
dynamic supervisor. Each worker updates a shared ETS table that
maintains a two-way mapping between worker pids and request ids.  The
workers also register with the `stats_hero_monitor' which monitors
each worker to ensure that the pid/reqid mapping is cleaned from the
ETS table when the worker exits. The top-level supervisor initializes
the ETS table.
